{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tflearn, h5py, cv2, itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.models.cnn_model import CNNModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(Y_test_labels, label_predictions):\n",
    "    cm = confusion_matrix(Y_test_labels[:,1], label_predictions[:,1])\n",
    "    TN = cm[0][0]\n",
    "    FP = cm[0][1]\n",
    "    FN = cm[1][0]\n",
    "    TP = cm[1][1]\n",
    "\n",
    "    precision = TP*1.0/(TP+FP)\n",
    "    recall = TP*1.0/(TP+FN)\n",
    "    specificity = TN*1.0/(TN+FP)\n",
    "    return precision, recall, specificity, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Purples):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "\n",
    "h5f = h5py.File('../src/data/train.h5', 'r')\n",
    "X_train_images = h5f['X']\n",
    "Y_train_labels = h5f['Y']\n",
    "\n",
    "print(\"X_train_images\", X_train_images.shape)\n",
    "print(\"Y_train_labels\", Y_train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "convnet  = CNNModel()\n",
    "network = convnet.define_network(X_train_images)\n",
    "model = tflearn.DNN(network, tensorboard_verbose=0, checkpoint_path=\"../ckpt/nodule3-classifier.tfl.ckpt\")\n",
    "model.load(\"../ckpt/nodule3-classifier.tfl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "\n",
    "preds = model.predict(X_train_images[:,:,:,:])\n",
    "print(\"preds\", preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get clusters\n",
    "\n",
    "pos_indicator = Y_train_labels[:,1]==1\n",
    "neg_indicator = Y_train_labels[:,0]==1\n",
    "\n",
    "pos_embeddings = preds[pos_indicator,:]\n",
    "neg_embeddings = preds[neg_indicator,:]\n",
    "print(pos_embeddings.shape, neg_embeddings.shape)\n",
    "\n",
    "avg_pos_embedding = pos_embeddings.mean(axis=0)\n",
    "avg_neg_embedding = neg_embeddings.mean(axis=0)\n",
    "print(\"avg_pos_embedding\", avg_pos_embedding)\n",
    "print(\"avg_neg_embedding\", avg_neg_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "\n",
    "h5f2 = h5py.File('../src/data/test.h5', 'r')\n",
    "X_test_images = h5f2['X']\n",
    "Y_test_labels = h5f2['Y']\n",
    "\n",
    "print(\"X_test_images\", X_test_images.shape)\n",
    "print(\"Y_test_labels\", Y_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "\n",
    "embeddings = model.predict(X_test_images[:,:,:,:])\n",
    "print(\"embeddings\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster\n",
    "\n",
    "pos_dists = ((embeddings-avg_pos_embedding)**2).sum(axis=1)[:,np.newaxis]\n",
    "neg_dists = ((embeddings-avg_neg_embedding)**2).sum(axis=1)[:,np.newaxis]\n",
    "dists = np.hstack([neg_dists, pos_dists])\n",
    "pred_indicies = np.argmin(dists, axis=1)\n",
    "neg_pred_indicies = np.argmax(dists, axis=1)\n",
    "\n",
    "print(\"neg_ratio:\", (pred_indicies==0).sum() / pred_indicies.size)\n",
    "print(\"pos_ratio:\", (pred_indicies==1).sum() / pred_indicies.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "\n",
    "predictions = np.hstack([neg_pred_indicies[:,np.newaxis], pred_indicies[:,np.newaxis]])\n",
    "precision, recall, specificity, cm = get_metrics(Y_test_labels, predictions)\n",
    "print(\"precision:\", precision)\n",
    "print(\"recall:\", recall)\n",
    "print(\"specificity:\", specificity)\n",
    "\n",
    "plt.figure(figsize=(10,15))\n",
    "plot_confusion_matrix(cm, classes=['no-nodule', 'nodule'], title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lungcancer",
   "language": "python",
   "name": "lungcancer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
